{'role': 'assistant', 'content': '<function_calls>\n<create-file file_path="medical-analysis-platform/lib/repositories/AIPromptOptimizationRepository.ts">\n/**\n * AI Prompt Optimization Repository\n * \n * This repository optimizes current and future prompts for the AI Analysis Repository.\n * It ensures prompts are:\n * - Relevant and accurate\n * - Cost-efficient (token optimization)\n * - Performance-optimized\n * - Contextually appropriate\n */\n\nimport { IRepository, RepositoryHealth } from \'./interfaces/IRepository\';\nimport { PrismaClient } from \'@prisma/client\';\n\nconst prisma = new PrismaClient();\n\nexport interface PromptTemplate {\n  id: string;\n  name: string;\n  category: PromptCategory;\n  template: string;\n  variables: PromptVariable[];\n  version: string;\n  optimizationMetrics: OptimizationMetrics;\n  performanceHistory: PerformanceRecord[];\n  createdAt: Date;\n  updatedAt: Date;\n  isActive: boolean;\n}\n\nexport type PromptCategory = \n  | \'document_analysis\'\n  | \'trend_analysis\'\n  | \'anomaly_detection\'\n  | \'summarization\'\n  | \'comparison\'\n  | \'recommendation\'\n  | \'risk_assessment\';\n\nexport interface PromptVariable {\n  name: string;\n  type: \'string\' | \'number\' | \'array\' | \'object\';\n  required: boolean;\n  description: string;\n  defaultValue?: any;\n  validation?: ValidationRule;\n}\n\nexport interface ValidationRule {\n  pattern?: string;\n  minLength?: number;\n  maxLength?: number;\n  min?: number;\n  max?: number;\n}\n\nexport interface OptimizationMetrics {\n  averageTokenCount: number;\n  averageResponseTime: number;\n  successRate: number;\n  costPerExecution: number;\n  relevanceScore: number;\n  clarityScore: number;\n  efficiencyScore: number;\n  overallScore: number;\n}\n\nexport interface PerformanceRecord {\n  timestamp: Date;\n  tokensUsed: number;\n  responseTime: number;\n  success: boolean;\n  userFeedback?: number; // 1-5 rating\n  errorMessage?: string;\n}\n\nexport interface OptimizationRequest {\n  promptId: string;\n  context: string;\n  targetMetrics: {\n    maxTokens?: number;\n    maxResponseTime?: number;\n    minRelevanceScore?: number;\n  };\n  constraints?: string[];\n}\n\nexport interface OptimizationResult {\n  originalPrompt: string;\n  optimizedPrompt: string;\n  improvements: Improvement[];\n  estimatedSavings: {\n    tokens: number;\n    cost: number;\n    time: number;\n  };\n  confidence: number;\n}\n\nexport interface Improvement {\n  type: \'token_reduction\' | \'clarity\' | \'specificity\' | \'structure\' | \'context\';\n  description: string;\n  impact: \'high\' | \'medium\' | \'low\';\n  before: string;\n  after: string;\n}\n\nexport class AIPromptOptimizationRepository implements IRepository<PromptTemplate> {\n  readonly name = \'AIPromptOptimizationRepository\';\n  readonly version = \'1.0.0\';\n  \n  private templates: Map<string, PromptTemplate> = new Map();\n  private optimizationCache: Map<string, OptimizationResult> = new Map();\n\n  async initialize(): Promise<void> {\n    console.log(`[${this.name}] Initializing...`);\n    \n    // Load default prompt templates\n    await this.loadDefaultTemplates();\n    \n    console.log(`[${this.name}] Loaded ${this.templates.size} prompt templates`);\n  }\n\n  /**\n   * Store prompt template\n   */\n  async store(key: string, data: PromptTemplate): Promise<void> {\n    this.templates.set(key, data);\n  }\n\n  /**\n   * Retrieve prompt template\n   */\n  async retrieve(key: string): Promise<PromptTemplate | null> {\n    return this.templates.get(key) || null;\n  }\n\n  /**\n   * Update prompt template\n   */\n  async update(key: string, data: Partial<PromptTemplate>): Promise<void> {\n    const existing = await this.retrieve(key);\n    if (!existing) {\n      throw new Error(`Template ${key} not found`);\n    }\n\n    const updated = {\n      ...existing,\n      ...data,\n      updatedAt: new Date()\n    };\n\n    await this.store(key, updated);\n  }\n\n  /**\n   * Delete prompt template\n   */\n  async delete(key: string): Promise<void> {\n    this.templates.delete(key);\n  }\n\n  /**\n   * Check if template exists\n   */\n  async exists(key: string): Promise<boolean> {\n    return this.templates.has(key);\n  }\n\n  /**\n   * Clear all templates\n   */\n  async clear(): Promise<void> {\n    this.templates.clear();\n    this.optimizationCache.clear();\n  }\n\n  /**\n   * Get repository health\n   */\n  async getHealth(): Promise<RepositoryHealth> {\n    const templateCount = this.templates.size;\n    const activeTemplates = Array.from(this.templates.values()).filter(t => t.isActive).length;\n    \n    const avgOptimizationScore = this.calculateAverageOptimizationScore();\n    \n    const issues: string[] = [];\n    if (activeTemplates === 0) {\n      issues.push(\'No active templates available\');\n    }\n    if (avgOptimizationScore < 0.7) {\n      issues.push(`Low average optimization score: ${avgOptimizationScore.toFixed(2)}`);\n    }\n\n    return {\n      status: issues.length === 0 ? \'healthy\' : \'degraded\',\n      lastCheck: new Date(),\n      metrics: {\n        itemCount: templateCount,\n        storageUsed: this.estimateStorageUsed(),\n        averageResponseTime: 0\n      },\n      issues: issues.length > 0 ? issues : undefined\n    };\n  }\n\n  /**\n   * Optimize a prompt for specific use case\n   */\n  async optimizePrompt(request: OptimizationRequest): Promise<OptimizationResult> {\n    const template = await this.retrieve(request.promptId);\n    if (!template) {\n      throw new Error(`Template ${request.promptId} not found`);\n    }\n\n    // Check cache first\n    const cacheKey = this.getCacheKey(request);\n    const cached = this.optimizationCache.get(cacheKey);\n    if (cached) {\n      return cached;\n    }\n\n    // Perform optimization\n    const result = await this.performOptimization(template, request);\n    \n    // Cache result\n    this.optimizationCache.set(cacheKey, result);\n    \n    // Update template metrics\n    await this.updateTemplateMetrics(request.promptId, result);\n\n    return result;\n  }\n\n  /**\n   * Get best prompt for a category\n   */\n  async getBestPrompt(category: PromptCategory): Promise<PromptTemplate | null> {\n    const categoryTemplates = Array.from(this.templates.values())\n      .filter(t => t.category === category && t.isActive);\n\n    if (categoryTemplates.length === 0) {\n      return null;\n    }\n\n    // Sort by overall optimization score\n    categoryTemplates.sort((a, b) => \n      b.optimizationMetrics.overallScore - a.optimizationMetrics.overallScore\n    );\n\n    return categoryTemplates[0];\n  }\n\n  /**\n   * Create new prompt template\n   */\n  async createTemplate(\n    name: string,\n    category: PromptCategory,\n    template: string,\n    variables: PromptVariable[]\n  ): Promise<PromptTemplate> {\n    const id = this.generateTemplateId();\n    \n    const newTemplate: PromptTemplate = {\n      id,\n      name,\n      category,\n      template,\n      variables,\n      version: \'1.0.0\',\n      optimizationMetrics: this.getDefaultMetrics(),\n      performanceHistory: [],\n      createdAt: new Date(),\n      updatedAt: new Date(),\n      isActive: true\n    };\n\n    await this.store(id, newTemplate);\n    return newTemplate;\n  }\n\n  /**\n   * Record performance of a prompt execution\n   */\n  async recordPerformance(\n    promptId: string,\n    record: PerformanceRecord\n  ): Promise<void> {\n    const template = await this.retrieve(promptId);\n    if (!template) return;\n\n    template.performanceHistory.push(record);\n    \n    // Keep only last 100 records\n    if (template.performanceHistory.length > 100) {\n      template.performanceHistory = template.performanceHistory.slice(-100);\n    }\n\n    // Recalculate metrics\n    template.optimizationMetrics = this.calculateMetrics(template.performanceHistory);\n    \n    await this.store(promptId, template);\n  }\n\n  /**\n   * Analyze prompt efficiency\n   */\n  async analyzeEfficiency(promptId: string): Promise<EfficiencyAnalysis> {\n    const template = await this.retrieve(promptId);\n    if (!template) {\n      throw new Error(`Template ${promptId} not found`);\n    }\n\n    const history = template.performanceHistory;\n    if (history.length === 0) {\n      return {\n        status: \'insufficient_data\',\n        recommendations: [\'Execute prompt multiple times to gather performance data\']\n      };\n    }\n\n    const recommendations: string[] = [];\n    const issues: string[] = [];\n\n    // Analyze token usage\n    const avgTokens = template.optimizationMetrics.averageTokenCount;\n    if (avgTokens > 2000) {\n      issues.push(\'High token usage detected\');\n      recommendations.push(\'Consider breaking down the prompt into smaller, focused queries\');\n    }\n\n    // Analyze response time\n    const avgResponseTime = template.optimizationMetrics.averageResponseTime;\n    if (avgResponseTime > 5000) {\n      issues.push(\'Slow response time detected\');\n      recommendations.push(\'Optimize prompt length and complexity\');\n    }\n\n    // Analyze success rate\n    const successRate = template.optimizationMetrics.successRate;\n    if (successRate < 0.9) {\n      issues.push(\'Low success rate detected\');\n      recommendations.push(\'Review prompt clarity and variable validation\');\n    }\n\n    return {\n      status: issues.length === 0 ? \'optimal\' : issues.length < 3 ? \'needs_improvement\' : \'poor\',\n      metrics: template.optimizationMetrics,\n      issues,\n      recommendations,\n      comparisonToAverage: this.compareToAverage(template)\n    };\n  }\n\n  /**\n   * Get prompt suggestions for a query\n   */\n  async suggestPrompts(query: string, category?: PromptCategory): Promise<PromptTemplate[]> {\n    let candidates = Array.from(this.templates.values()).filter(t => t.isActive);\n\n    if (category) {\n      candidates = candidates.filter(t => t.category === category);\n    }\n\n    // Score each template based on relevance to query\n    const scored = candidates.map(template => ({\n      template,\n      score: this.calculateRelevanceScore(template, query)\n    }));\n\n    // Sort by score and return top 3\n    scored.sort((a, b) => b.score - a.score);\n    return scored.slice(0, 3).map(s => s.template);\n  }\n\n  // Private helper methods\n\n  private async loadDefaultTemplates(): Promise<void> {\n    // Document Analysis Template\n    await this.createTemplate(\n      \'Standard Document Analysis\',\n      \'document_analysis\',\n      `Analyze the following medical document and provide:\n1. Key findings and important information\n2. Any abnormal values or concerning results\n3. Relevant context from patient history\n4. Recommendations for follow-up\n\nDocument Type: {{documentType}}\nDocument Date: {{documentDate}}\nExtracted Data: {{extractedData}}\nPatient Context: {{patientContext}}\n\nProvide a comprehensive analysis focusing on medical accuracy and actionable insights.`,\n      [\n        { name: \'documentType\', type: \'string\', required: true, description: \'Type of medical document\' },\n        { name: \'documentDate\', type: \'string\', required: true, description: \'Date of the document\' },\n        { name: \'extractedData\', type: \'string\', required: true, description: \'Extracted data from OCR\' },\n        { name: \'patientContext\', type: \'string\', required: false, description: \'Relevant patient history\' }\n      ]\n    );\n\n    // Trend Analysis Template\n    await this.createTemplate(\n      \'Trend Analysis\',\n      \'trend_analysis\',\n      `Analyze trends in the following medical data over time:\n\n{{dataPoints}}\n\nIdentify:\n1. Significant changes or patterns\n2. Values moving toward or away from normal ranges\n3. Potential concerns or improvements\n4. Recommendations for monitoring\n\nFocus on clinically significant trends and provide clear explanations.`,\n      [\n        { name: \'dataPoints\', type: \'array\', required: true, description: \'Time-series data points\' }\n      ]\n    );\n\n    // Anomaly Detection Template\n    await this.createTemplate(\n      \'Anomaly Detection\',\n      \'anomaly_detection\',\n      `Review the following medical data for anomalies:\n\nCurrent Results: {{currentResults}}\nReference Ranges: {{referenceRanges}}\nHistorical Data: {{historicalData}}\n\nIdentify:\n1. Values outside normal ranges\n2. Unexpected changes from baseline\n3. Potential data quality issues\n4. Clinical significance of anomalies\n\nPrioritize findings by severity and clinical importance.`,\n      [\n        { name: \'currentResults\', type: \'object\', required: true, description: \'Current test results\' },\n        { name: \'referenceRanges\', type: \'object\', required: true, description: \'Normal reference ranges\' },\n        { name: \'historicalData\', type: \'array\', required: false, description: \'Previous results for comparison\' }\n      ]\n    );\n  }\n\n  private async performOptimization(\n    template: PromptTemplate,\n    request: OptimizationRequest\n  ): Promise<OptimizationResult> {\n    const improvements: Improvement[] = [];\n    let optimizedPrompt = template.template;\n\n    // Token reduction optimization\n    const tokenReduction = this.optimizeForTokens(optimizedPrompt);\n    if (tokenReduction.improved) {\n      improvements.push({\n        type: \'token_reduction\',\n        description: \'Reduced unnecessary verbosity while maintaining clarity\',\n        impact: \'high\',\n        before: optimizedPrompt,\n        after: tokenReduction.result\n      });\n      optimizedPrompt = tokenReduction.result;\n    }\n\n    // Clarity optimization\n    const clarityImprovement = this.optimizeForClarity(optimizedPrompt);\n    if (clarityImprovement.improved) {\n      improvements.push({\n        type: \'clarity\',\n        description: \'Improved instruction clarity and specificity\',\n        impact: \'medium\',\n        before: optimizedPrompt,\n        after: clarityImprovement.result\n      });\n      optimizedPrompt = clarityImprovement.result;\n    }\n\n    // Structure optimization\n    const structureImprovement = this.optimizeStructure(optimizedPrompt);\n    if (structureImprovement.improved) {\n      improvements.push({\n        type: \'structure\',\n        description: \'Improved prompt structure and organization\',\n        impact: \'medium\',\n        before: optimizedPrompt,\n        after: structureImprovement.result\n      });\n      optimizedPrompt = structureImprovement.result;\n    }\n\n    const originalTokens = this.estimateTokens(template.template);\n    const optimizedTokens = this.estimateTokens(optimizedPrompt);\n    const tokenSavings = originalTokens - optimizedTokens;\n\n    return {\n      originalPrompt: template.template,\n      optimizedPrompt,\n      improvements,\n      estimatedSavings: {\n        tokens: tokenSavings,\n        cost: tokenSavings * 0.00002, // Approximate cost per token\n        time: tokenSavings * 0.001 // Approximate time per token\n      },\n      confidence: improvements.length > 0 ? 0.85 : 0.5\n    };\n  }\n\n  private optimizeForTokens(prompt: string): { improved: boolean; result: string } {\n    let optimized = prompt;\n    let improved = false;\n\n    // Remove redundant phrases\n    const redundantPhrases = [\n      \'please \',\n      \'kindly \',\n      \'I would like you to \',\n      \'Could you \',\n      \'Would you \'\n    ];\n\n    for (const phrase of redundantPhrases) {\n      if (optimized.includes(phrase)) {\n        optimized = optimized.replace(new RegExp(phrase, \'gi\'), \'\');\n        improved = true;\n      }\n    }\n\n    // Simplify verbose instructions\n    optimized = optimized.replace(/in order to/gi, \'to\');\n    optimized = optimized.replace(/due to the fact that/gi, \'because\');\n    optimized = optimized.replace(/at this point in time/gi, \'now\');\n\n    return { improved, result: optimized };\n  }\n\n  private optimizeForClarity(prompt: string): { improved: boolean; result: string } {\n    // This is a simplified version - in production, this would use NLP\n    return { improved: false, result: prompt };\n  }\n\n  private optimizeStructure(prompt: string): { improved: boolean; result: string } {\n    // This is a simplified version - in production, this would analyze structure\n    return { improved: false, result: prompt };\n  }\n\n  private estimateTokens(text: string): number {\n    // Rough estimation: ~4 characters per token\n    return Math.ceil(text.length / 4);\n  }\n\n  private calculateMetrics(history: PerformanceRecord[]): OptimizationMetrics {\n    if (history.length === 0) {\n      return this.getDefaultMetrics();\n    }\n\n    const avgTokens = history.reduce((sum, r) => sum + r.tokensUsed, 0) / history.length;\n    const avgResponseTime = history.reduce((sum, r) => sum + r.responseTime, 0) / history.length;\n    const successRate = history.filter(r => r.success).length / history.length;\n    const avgFeedback = history\n      .filter(r => r.userFeedback !== undefined)\n      .reduce((sum, r) => sum + (r.userFeedback || 0), 0) / \n      history.filter(r => r.userFeedback !== undefined).length || 0;\n\n    const relevanceScore = avgFeedback / 5; // Normalize to 0-1\n    const clarityScore = successRate;\n    const efficiencyScore = Math.max(0, 1 - (avgTokens / 4000)); // Penalize high token usage\n    const overallScore = (relevanceScore + clarityScore + efficiencyScore) / 3;\n\n    return {\n      averageTokenCount: avgTokens,\n      averageResponseTime: avgResponseTime,\n      successRate,\n      costPerExecution: avgTokens * 0.00002,\n      relevanceScore,\n      clarityScore,\n      efficiencyScore,\n      overallScore\n    };\n  }\n\n  private getDefaultMetrics(): OptimizationMetrics {\n    return {\n      averageTokenCount: 0,\n      averageResponseTime: 0,\n      successRate: 0,\n      costPerExecution: 0,\n      relevanceScore: 0,\n      clarityScore: 0,\n      efficiencyScore: 0,\n      overallScore: 0\n    };\n  }\n\n  private calculateAverageOptimizationScore(): number {\n    const templates = Array.from(this.templates.values());\n    if (templates.length === 0) return 0;\n\n    const totalScore = templates.reduce((sum, t) => sum + t.optimizationMetrics.overallScore, 0);\n    return totalScore / templates.length;\n  }\n\n  private estimateStorageUsed(): number {\n    return this.templates.size * 5000; // ~5KB per template\n  }\n\n  private generateTemplateId(): string {\n    return `prompt_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n  }\n\n  private getCacheKey(request: OptimizationRequest): string {\n    return `${request.promptId}_${JSON.stringify(request.targetMetrics)}`;\n  }\n\n  private async updateTemplateMetrics(promptId: string, result: OptimizationResult): Promise<void> {\n    // Update template with optimization results\n    const template = await this.retrieve(promptId);\n    if (!template) return;\n\n    // This would update metrics based on optimization results\n    await this.store(promptId, template);\n  }\n\n  private compareToAverage(template: PromptTemplate): any {\n    const avgScore = this.calculateAverageOptimizationScore();\n    return {\n      betterThanAverage: template.optimizationMetrics.overallScore > avgScore,\n      difference: template.optimizationMetrics.overallScore - avgScore\n    };\n  }\n\n  private calculateRelevanceScore(template: PromptTemplate, query: string): number {\n    // Simple keyword matching - in production, use embeddings\n    const queryLower = query.toLowerCase();\n    const templateLower = template.template.toLowerCase();\n    \n    const queryWords = queryLower.split(/\\s+/);\n    const matches = queryWords.filter(word => templateLower.includes(word)).length;\n    \n    return matches / queryWords.length;\n  }\n}\n\nexport interface EfficiencyAnalysis {\n  status: \'optimal\' | \'needs_improvement\' | \'poor\' | \'insufficient_data\';\n  metrics?: OptimizationMetrics;\n  issues?: string[];\n  recommendations: string[];\n  comparisonToAverage?: any;\n}\n\nexport const aiPromptOptimizationRepository = new AIPromptOptimizationRepository();\n</create-file>\n</function_calls>'}