{'role': 'assistant', 'content': 'Now let\'s create the AI Development Chat Service:\n\n<function_calls>\n<create-file file_path="medical-analysis-platform/lib/services/AIDevChatService.ts">\n/**\n * AI Development Chat Service\n * \n * Specialized chat service for development assistance using multiple AI providers.\n * Supports code generation, debugging, architecture discussions, and more.\n */\n\nimport { PrismaClient } from \'@prisma/client\';\nimport {\n  AIProvider,\n  AIModel,\n  AICompletionRequest,\n  AICompletionResponse,\n  AIStreamChunk\n} from \'@/lib/types/ai-provider\';\nimport { getProviderManager, ProviderManager } from \'@/lib/providers/ProviderManager\';\n\nexport enum DevChatMode {\n  CODE_GENERATION = \'CODE_GENERATION\',\n  DEBUGGING = \'DEBUGGING\',\n  ARCHITECTURE = \'ARCHITECTURE\',\n  DOCUMENTATION = \'DOCUMENTATION\',\n  CODE_REVIEW = \'CODE_REVIEW\',\n  TEST_GENERATION = \'TEST_GENERATION\',\n  REFACTORING = \'REFACTORING\',\n  GENERAL = \'GENERAL\'\n}\n\nexport interface DevChatRequest {\n  conversationId?: string;\n  userId: string;\n  message: string;\n  mode?: DevChatMode;\n  provider?: string; // Specific provider to use\n  context?: {\n    codeSnippet?: string;\n    language?: string;\n    framework?: string;\n    errorMessage?: string;\n    fileContext?: string[];\n  };\n}\n\nexport interface DevChatResponse {\n  conversationId: string;\n  messageId: string;\n  content: string;\n  provider: AIProvider;\n  model: AIModel;\n  tokens: {\n    prompt: number;\n    completion: number;\n    total: number;\n  };\n  cost: number;\n  processingTime: number;\n  metadata?: {\n    mode: DevChatMode;\n    suggestions?: string[];\n  };\n}\n\nexport class AIDevChatService {\n  private prisma: PrismaClient;\n  private providerManager: ProviderManager;\n\n  constructor() {\n    this.prisma = new PrismaClient();\n    this.providerManager = getProviderManager();\n  }\n\n  /**\n   * Process a development chat request\n   */\n  async chat(request: DevChatRequest): Promise<DevChatResponse> {\n    const startTime = Date.now();\n\n    try {\n      // Get or create conversation\n      const conversation = await this.getOrCreateConversation(\n        request.conversationId,\n        request.userId\n      );\n\n      // Build system prompt based on mode\n      const systemPrompt = this.getSystemPrompt(request.mode || DevChatMode.GENERAL);\n\n      // Build messages\n      const messages = await this.buildMessages(\n        conversation.id,\n        systemPrompt,\n        request.message,\n        request.context\n      );\n\n      // Determine which provider to use\n      if (request.provider) {\n        this.providerManager.switchProvider(request.provider);\n      }\n\n      const provider = this.providerManager.getActiveProvider();\n\n      // Create completion request\n      const completionRequest: AICompletionRequest = {\n        messages,\n        model: provider.model,\n        maxTokens: 4096,\n        temperature: 0.7,\n        stream: false\n      };\n\n      // Get completion\n      const response = await this.providerManager.complete(completionRequest);\n\n      // Save messages to database\n      await this.saveMessage(\n        conversation.id,\n        \'user\',\n        request.message,\n        response.usage.promptTokens\n      );\n\n      await this.saveMessage(\n        conversation.id,\n        \'assistant\',\n        response.content,\n        response.usage.completionTokens\n      );\n\n      // Update conversation\n      await this.updateConversation(conversation.id, response.cost);\n\n      // Track interaction\n      await this.trackInteraction(\n        conversation.id,\n        request.userId,\n        provider.provider,\n        provider.model,\n        response.usage,\n        response.cost,\n        Date.now() - startTime\n      );\n\n      const processingTime = Date.now() - startTime;\n\n      return {\n        conversationId: conversation.id,\n        messageId: conversation.id, // Use conversation ID as message ID for now\n        content: response.content,\n        provider: provider.provider,\n        model: provider.model,\n        tokens: response.usage,\n        cost: response.cost,\n        processingTime,\n        metadata: {\n          mode: request.mode || DevChatMode.GENERAL\n        }\n      };\n    } catch (error: any) {\n      console.error(\'Dev chat error:\', error);\n      throw new Error(`Dev chat processing failed: ${error.message}`);\n    }\n  }\n\n  /**\n   * Stream a development chat request\n   */\n  async *streamChat(request: DevChatRequest): AsyncGenerator<string> {\n    try {\n      // Get or create conversation\n      const conversation = await this.getOrCreateConversation(\n        request.conversationId,\n        request.userId\n      );\n\n      // Build system prompt based on mode\n      const systemPrompt = this.getSystemPrompt(request.mode || DevChatMode.GENERAL);\n\n      // Build messages\n      const messages = await this.buildMessages(\n        conversation.id,\n        systemPrompt,\n        request.message,\n        request.context\n      );\n\n      // Determine which provider to use\n      if (request.provider) {\n        this.providerManager.switchProvider(request.provider);\n      }\n\n      const provider = this.providerManager.getActiveProvider();\n\n      // Create completion request\n      const completionRequest: AICompletionRequest = {\n        messages,\n        model: provider.model,\n        maxTokens: 4096,\n        temperature: 0.7,\n        stream: true\n      };\n\n      // Stream response\n      let fullResponse = \'\';\n      for await (const chunk of this.providerManager.stream(completionRequest)) {\n        if (chunk.content) {\n          fullResponse += chunk.content;\n          yield chunk.content;\n        }\n      }\n\n      // Save messages after streaming completes\n      const promptTokens = provider.countTokens(messages.map(m => m.content).join(\'\\n\'));\n      const completionTokens = provider.countTokens(fullResponse);\n      const cost = provider.calculateCost(promptTokens, completionTokens);\n\n      await this.saveMessage(conversation.id, \'user\', request.message, promptTokens);\n      await this.saveMessage(conversation.id, \'assistant\', fullResponse, completionTokens);\n      await this.updateConversation(conversation.id, cost);\n    } catch (error: any) {\n      console.error(\'Dev chat streaming error:\', error);\n      throw new Error(`Dev chat streaming failed: ${error.message}`);\n    }\n  }\n\n  /**\n   * Switch AI provider\n   */\n  switchProvider(providerName: string): void {\n    this.providerManager.switchProvider(providerName);\n  }\n\n  /**\n   * Get available providers\n   */\n  getAvailableProviders(): Array<{\n    name: string;\n    provider: AIProvider;\n    model: AIModel;\n    isActive: boolean;\n  }> {\n    return this.providerManager.listProviders();\n  }\n\n  /**\n   * Get active provider info\n   */\n  getActiveProviderInfo() {\n    return this.providerManager.getProviderInfo();\n  }\n\n  /**\n   * Get conversation history\n   */\n  async getConversationHistory(conversationId: string) {\n    return await this.prisma.chatConversation.findUnique({\n      where: { id: conversationId },\n      include: {\n        messages: {\n          orderBy: { createdAt: \'asc\' }\n        }\n      }\n    });\n  }\n\n  /**\n   * Get user conversations\n   */\n  async getUserConversations(userId: string) {\n    return await this.prisma.chatConversation.findMany({\n      where: { userId },\n      orderBy: { updatedAt: \'desc\' },\n      include: {\n        messages: {\n          take: 1,\n          orderBy: { createdAt: \'desc\' }\n        }\n      }\n    });\n  }\n\n  /**\n   * Delete conversation\n   */\n  async deleteConversation(conversationId: string) {\n    await this.prisma.chatMessage.deleteMany({\n      where: { conversationId }\n    });\n\n    await this.prisma.chatConversation.delete({\n      where: { id: conversationId }\n    });\n  }\n\n  /**\n   * Get or create conversation\n   */\n  private async getOrCreateConversation(\n    conversationId: string | undefined,\n    userId: string\n  ) {\n    if (conversationId) {\n      const conversation = await this.prisma.chatConversation.findUnique({\n        where: { id: conversationId }\n      });\n\n      if (conversation) {\n        return conversation;\n      }\n    }\n\n    // Create new conversation\n    return await this.prisma.chatConversation.create({\n      data: {\n        userId,\n        title: \'Dev Chat\',\n        totalTokens: 0,\n        totalCost: 0,\n        isActive: true\n      }\n    });\n  }\n\n  /**\n   * Build messages for completion\n   */\n  private async buildMessages(\n    conversationId: string,\n    systemPrompt: string,\n    currentMessage: string,\n    context?: DevChatRequest[\'context\']\n  ) {\n    const messages: AICompletionRequest[\'messages\'] = [];\n\n    // Add system prompt\n    messages.push({ role: \'system\', content: systemPrompt });\n\n    // Get conversation history\n    const history = await this.prisma.chatMessage.findMany({\n      where: { conversationId },\n      orderBy: { createdAt: \'asc\' },\n      take: 10 // Last 10 messages\n    });\n\n    for (const msg of history) {\n      messages.push({\n        role: msg.role.toLowerCase() as \'user\' | \'assistant\',\n        content: msg.content\n      });\n    }\n\n    // Add context if provided\n    let messageWithContext = currentMessage;\n    if (context) {\n      if (context.codeSnippet) {\n        messageWithContext += `\\n\\n\\`\\`\\`${context.language || \'\'}\\n${context.codeSnippet}\\n\\`\\`\\``;\n      }\n      if (context.errorMessage) {\n        messageWithContext += `\\n\\nError: ${context.errorMessage}`;\n      }\n      if (context.fileContext && context.fileContext.length > 0) {\n        messageWithContext += `\\n\\nRelated files: ${context.fileContext.join(\', \')}`;\n      }\n    }\n\n    // Add current message\n    messages.push({ role: \'user\', content: messageWithContext });\n\n    return messages;\n  }\n\n  /**\n   * Get system prompt based on mode\n   */\n  private getSystemPrompt(mode: DevChatMode): string {\n    const prompts: Record<DevChatMode, string> = {\n      [DevChatMode.CODE_GENERATION]: `You are an expert software developer assistant specializing in code generation.\nYour role is to write clean, efficient, well-documented code following best practices.\nAlways explain your code and provide usage examples.\nConsider edge cases, error handling, and performance.`,\n\n      [DevChatMode.DEBUGGING]: `You are an expert debugging assistant.\nYour role is to help identify and fix bugs in code.\nAnalyze error messages, stack traces, and code to find root causes.\nProvide clear explanations and step-by-step solutions.\nSuggest preventive measures to avoid similar bugs.`,\n\n      [DevChatMode.ARCHITECTURE]: `You are a software architecture expert.\nYour role is to help design scalable, maintainable system architectures.\nConsider design patterns, best practices, and trade-offs.\nProvide diagrams, explanations, and implementation guidance.\nFocus on long-term maintainability and scalability.`,\n\n      [DevChatMode.DOCUMENTATION]: `You are a technical documentation specialist.\nYour role is to create clear, comprehensive documentation.\nWrite for different audiences: developers, users, and stakeholders.\nInclude examples, diagrams, and best practices.\nMake documentation easy to understand and maintain.`,\n\n      [DevChatMode.CODE_REVIEW]: `You are an experienced code reviewer.\nYour role is to review code for quality, security, and best practices.\nIdentify bugs, performance issues, and maintainability concerns.\nProvide constructive feedback with specific suggestions.\nHighlight both strengths and areas for improvement.`,\n\n      [DevChatMode.TEST_GENERATION]: `You are a testing expert.\nYour role is to generate comprehensive test cases.\nWrite unit tests, integration tests, and edge case tests.\nFollow testing best practices and use appropriate frameworks.\nEnsure high code coverage and meaningful assertions.`,\n\n      [DevChatMode.REFACTORING]: `You are a code refactoring specialist.\nYour role is to improve code quality without changing functionality.\nFocus on readability, maintainability, and performance.\nApply design patterns and best practices.\nExplain the benefits of each refactoring.`,\n\n      [DevChatMode.GENERAL]: `You are a helpful AI development assistant.\nYour role is to help with any development-related questions.\nProvide clear, accurate, and practical advice.\nUse examples and explanations to make concepts clear.\nBe concise but thorough in your responses.`\n    };\n\n    return prompts[mode];\n  }\n\n  /**\n   * Save message to database\n   */\n  private async saveMessage(\n    conversationId: string,\n    role: \'user\' | \'assistant\',\n    content: string,\n    tokens: number\n  ) {\n    return await this.prisma.chatMessage.create({\n      data: {\n        conversationId,\n        role: role.toUpperCase() as any,\n        content,\n        tokens\n      }\n    });\n  }\n\n  /**\n   * Update conversation totals\n   */\n  private async updateConversation(conversationId: string, additionalCost: number) {\n    const conversation = await this.prisma.chatConversation.findUnique({\n      where: { id: conversationId },\n      include: { messages: true }\n    });\n\n    if (!conversation) return;\n\n    const totalTokens = conversation.messages.reduce(\n      (sum, msg) => sum + msg.tokens,\n      0\n    );\n\n    await this.prisma.chatConversation.update({\n      where: { id: conversationId },\n      data: {\n        totalTokens,\n        totalCost: conversation.totalCost + additionalCost,\n        updatedAt: new Date()\n      }\n    });\n  }\n\n  /**\n   * Track AI interaction\n   */\n  private async trackInteraction(\n    conversationId: string,\n    userId: string,\n    provider: AIProvider,\n    model: AIModel,\n    usage: { promptTokens: number; completionTokens: number; totalTokens: number },\n    cost: number,\n    responseTime: number\n  ) {\n    await this.prisma.aIInteraction.create({\n      data: {\n        userId,\n        interactionType: \'DEV_CHAT\',\n        model: `${provider}:${model}`,\n        promptTokens: usage.promptTokens,\n        completionTokens: usage.completionTokens,\n        totalTokens: usage.totalTokens,\n        cost,\n        responseTime,\n        success: true,\n        metadata: { conversationId, provider, model }\n      }\n    });\n  }\n\n  /**\n   * Cleanup resources\n   */\n  async cleanup() {\n    await this.prisma.$disconnect();\n  }\n}\n</create-file>\n</function_calls>'}