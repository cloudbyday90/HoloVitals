{'role': 'assistant', 'content': 'Great! Now let\'s create the Claude Provider:\n\n<function_calls>\n<create-file file_path="medical-analysis-platform/lib/providers/ClaudeProvider.ts">\n/**\n * Claude (Anthropic) AI Provider\n * \n * Implementation of IAIProvider for Anthropic\'s Claude models.\n * Supports Claude 3 Opus, Sonnet, Haiku, and Claude 3.5 Sonnet.\n */\n\nimport Anthropic from \'@anthropic-ai/sdk\';\nimport {\n  IAIProvider,\n  AIProvider,\n  AIModel,\n  AICompletionRequest,\n  AICompletionResponse,\n  AIStreamChunk,\n  AIProviderConfig,\n  AIProviderCapabilities,\n  AIProviderCosts,\n  MODEL_CAPABILITIES,\n  MODEL_COSTS,\n  AIProviderError,\n  RateLimitError,\n  AuthenticationError,\n  InvalidRequestError\n} from \'@/lib/types/ai-provider\';\n\nexport class ClaudeProvider implements IAIProvider {\n  private client: Anthropic;\n  private config: AIProviderConfig;\n\n  readonly provider = AIProvider.CLAUDE;\n  readonly model: AIModel;\n  readonly capabilities: AIProviderCapabilities;\n  readonly costs: AIProviderCosts;\n\n  constructor(config: AIProviderConfig) {\n    if (config.provider !== AIProvider.CLAUDE) {\n      throw new Error(\'Invalid provider for ClaudeProvider\');\n    }\n\n    this.config = config;\n    this.model = config.model;\n    this.capabilities = MODEL_CAPABILITIES[config.model];\n    this.costs = MODEL_COSTS[config.model];\n\n    // Initialize Anthropic client\n    this.client = new Anthropic({\n      apiKey: config.apiKey,\n      baseURL: config.baseURL,\n      timeout: config.timeout || 60000,\n    });\n  }\n\n  /**\n   * Complete a chat request\n   */\n  async complete(request: AICompletionRequest): Promise<AICompletionResponse> {\n    try {\n      // Convert messages to Claude format\n      const { system, messages } = this.convertMessages(request.messages);\n\n      // Create completion\n      const response = await this.client.messages.create({\n        model: request.model,\n        max_tokens: request.maxTokens || this.config.maxTokens || 4096,\n        temperature: request.temperature ?? this.config.temperature ?? 0.7,\n        top_p: request.topP ?? this.config.topP ?? 1,\n        system: system || undefined,\n        messages: messages as any,\n        stop_sequences: request.stopSequences,\n      });\n\n      // Extract content\n      const content = response.content\n        .filter(block => block.type === \'text\')\n        .map(block => (block as any).text)\n        .join(\'\');\n\n      // Calculate cost\n      const cost = this.calculateCost(\n        response.usage.input_tokens,\n        response.usage.output_tokens\n      );\n\n      return {\n        id: response.id,\n        content,\n        model: request.model,\n        provider: this.provider,\n        usage: {\n          promptTokens: response.usage.input_tokens,\n          completionTokens: response.usage.output_tokens,\n          totalTokens: response.usage.input_tokens + response.usage.output_tokens\n        },\n        cost,\n        finishReason: this.mapStopReason(response.stop_reason),\n        metadata: {\n          stopSequence: response.stop_sequence,\n          model: response.model\n        }\n      };\n    } catch (error: any) {\n      throw this.handleError(error);\n    }\n  }\n\n  /**\n   * Stream a chat request\n   */\n  async *stream(request: AICompletionRequest): AsyncGenerator<AIStreamChunk> {\n    try {\n      // Convert messages to Claude format\n      const { system, messages } = this.convertMessages(request.messages);\n\n      // Create streaming completion\n      const stream = await this.client.messages.stream({\n        model: request.model,\n        max_tokens: request.maxTokens || this.config.maxTokens || 4096,\n        temperature: request.temperature ?? this.config.temperature ?? 0.7,\n        top_p: request.topP ?? this.config.topP ?? 1,\n        system: system || undefined,\n        messages: messages as any,\n        stop_sequences: request.stopSequences,\n      });\n\n      // Stream chunks\n      for await (const chunk of stream) {\n        if (chunk.type === \'content_block_delta\') {\n          const delta = chunk.delta;\n          if (delta.type === \'text_delta\') {\n            yield {\n              content: delta.text\n            };\n          }\n        } else if (chunk.type === \'message_stop\') {\n          yield {\n            content: \'\',\n            finishReason: \'stop\'\n          };\n        }\n      }\n    } catch (error: any) {\n      throw this.handleError(error);\n    }\n  }\n\n  /**\n   * Count tokens in text\n   * Note: Claude doesn\'t provide a token counting API, so we estimate\n   */\n  countTokens(text: string): number {\n    // Rough estimation: 1 token â‰ˆ 4 characters for English text\n    // Claude\'s actual tokenization may differ\n    return Math.ceil(text.length / 4);\n  }\n\n  /**\n   * Calculate cost based on token usage\n   */\n  calculateCost(promptTokens: number, completionTokens: number): number {\n    const promptCost = (promptTokens / 1_000_000) * this.costs.promptCostPer1M;\n    const completionCost = (completionTokens / 1_000_000) * this.costs.completionCostPer1M;\n    return promptCost + completionCost;\n  }\n\n  /**\n   * Validate API key\n   */\n  async validateApiKey(): Promise<boolean> {\n    try {\n      // Try a minimal request to validate the key\n      await this.client.messages.create({\n        model: this.model,\n        max_tokens: 10,\n        messages: [{ role: \'user\', content: \'Hi\' }]\n      });\n      return true;\n    } catch (error: any) {\n      if (error.status === 401) {\n        return false;\n      }\n      // Other errors might be rate limits, etc., but key is valid\n      return true;\n    }\n  }\n\n  /**\n   * Update configuration\n   */\n  updateConfig(config: Partial<AIProviderConfig>): void {\n    this.config = { ...this.config, ...config };\n    \n    // Reinitialize client if API key or baseURL changed\n    if (config.apiKey || config.baseURL || config.timeout) {\n      this.client = new Anthropic({\n        apiKey: this.config.apiKey,\n        baseURL: this.config.baseURL,\n        timeout: this.config.timeout || 60000,\n      });\n    }\n  }\n\n  /**\n   * Get current configuration\n   */\n  getConfig(): AIProviderConfig {\n    return { ...this.config };\n  }\n\n  /**\n   * Convert messages to Claude format\n   * Claude requires system messages to be separate\n   */\n  private convertMessages(messages: AICompletionRequest[\'messages\']): {\n    system: string | null;\n    messages: Array<{ role: \'user\' | \'assistant\'; content: string }>;\n  } {\n    let system: string | null = null;\n    const convertedMessages: Array<{ role: \'user\' | \'assistant\'; content: string }> = [];\n\n    for (const message of messages) {\n      if (message.role === \'system\') {\n        // Combine all system messages\n        system = system ? `${system}\\n\\n${message.content}` : message.content;\n      } else {\n        convertedMessages.push({\n          role: message.role as \'user\' | \'assistant\',\n          content: message.content\n        });\n      }\n    }\n\n    return { system, messages: convertedMessages };\n  }\n\n  /**\n   * Map Claude\'s stop reason to our standard format\n   */\n  private mapStopReason(\n    stopReason: string | null\n  ): \'stop\' | \'length\' | \'content_filter\' | \'tool_use\' {\n    switch (stopReason) {\n      case \'end_turn\':\n        return \'stop\';\n      case \'max_tokens\':\n        return \'length\';\n      case \'stop_sequence\':\n        return \'stop\';\n      case \'tool_use\':\n        return \'tool_use\';\n      default:\n        return \'stop\';\n    }\n  }\n\n  /**\n   * Handle errors from Claude API\n   */\n  private handleError(error: any): AIProviderError {\n    if (error instanceof Anthropic.APIError) {\n      const status = error.status;\n      const message = error.message;\n\n      if (status === 401) {\n        return new AuthenticationError(this.provider);\n      } else if (status === 429) {\n        return new RateLimitError(this.provider);\n      } else if (status === 400) {\n        return new InvalidRequestError(this.provider, message);\n      } else {\n        return new AIProviderError(\n          `Claude API error: ${message}`,\n          this.provider,\n          status,\n          error\n        );\n      }\n    }\n\n    return new AIProviderError(\n      `Unexpected error: ${error.message}`,\n      this.provider,\n      undefined,\n      error\n    );\n  }\n}\n</create-file>\n</function_calls>'}