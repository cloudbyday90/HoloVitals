{'role': 'assistant', 'content': '# Phase 3: Service Implementation - Let\'s Begin!\n\nPerfect! Now that Phase 2 (Database Setup) is complete, let\'s start implementing the core services for HoloVitals. \n\n## üìã Phase 3 Overview\n\nWe\'ll implement **4 core services** that power the AI-driven medical document analysis with cost optimization:\n\n### Services to Build:\n\n1. **LightweightChatbotService** (Week 1) - Priority: HIGH\n2. **ContextOptimizerService** (Week 1) - Priority: HIGH  \n3. **AnalysisQueueService** (Week 2) - Priority: MEDIUM\n4. **InstanceProvisionerService** (Week 2-3) - Priority: MEDIUM\n\n---\n\n## üéØ Starting with Service #1: LightweightChatbotService\n\nLet me create a comprehensive implementation plan and start building:\n\n<function_calls>\n<create-file file_path="medical-analysis-platform/PHASE_3_PLAN.md">\n# Phase 3: Service Implementation Plan\n\n## Overview\nImplement the four core services that enable HoloVitals\' AI-powered medical document analysis with intelligent cost optimization.\n\n---\n\n## Service 1: LightweightChatbotService ‚è≥\n\n### Purpose\nFast AI responses for 80% of user queries using GPT-3.5 Turbo, with automatic escalation to heavy-duty analysis when needed.\n\n### Key Features\n- ‚úÖ <2 second response time\n- ‚úÖ Uses GPT-3.5 Turbo for cost efficiency\n- ‚úÖ Conversation context management\n- ‚úÖ Query classification (simple vs complex)\n- ‚úÖ Automatic escalation triggers\n- ‚úÖ Response streaming support\n- ‚úÖ Error handling and retries\n\n### Implementation Tasks\n- [ ] Create service class structure\n- [ ] Integrate OpenAI API\n- [ ] Implement conversation context management\n- [ ] Add query classification logic\n- [ ] Build escalation triggers\n- [ ] Add response streaming\n- [ ] Implement error handling\n- [ ] Create API endpoints\n- [ ] Write unit tests\n- [ ] Add integration tests\n\n### Files to Create\n1. `lib/services/LightweightChatbotService.ts` - Main service\n2. `lib/types/chatbot.ts` - Type definitions\n3. `app/api/chat/route.ts` - API endpoint\n4. `lib/utils/openai.ts` - OpenAI client wrapper\n5. `__tests__/services/LightweightChatbotService.test.ts` - Tests\n\n### Database Tables Used\n- `chat_conversations`\n- `chat_messages`\n- `ai_interactions`\n- `chatbot_costs`\n\n### Estimated Time: 2-3 days\n\n---\n\n## Service 2: ContextOptimizerService ‚è≥\n\n### Purpose\nReduce token usage by 40% through intelligent context management and relevance scoring.\n\n### Key Features\n- ‚úÖ Smart document chunking\n- ‚úÖ Relevance scoring for context selection\n- ‚úÖ Token counting and optimization\n- ‚úÖ Context window management (4K, 8K, 16K, 32K)\n- ‚úÖ Context compression\n- ‚úÖ Performance metrics tracking\n\n### Implementation Tasks\n- [ ] Create context analysis engine\n- [ ] Implement relevance scoring algorithm\n- [ ] Build token counting utilities\n- [ ] Add context compression logic\n- [ ] Create context caching system\n- [ ] Implement performance metrics\n- [ ] Create API endpoints\n- [ ] Write unit tests\n- [ ] Add integration tests\n\n### Files to Create\n1. `lib/services/ContextOptimizerService.ts` - Main service\n2. `lib/types/context.ts` - Type definitions\n3. `lib/utils/tokenCounter.ts` - Token counting utilities\n4. `lib/utils/relevanceScorer.ts` - Relevance scoring\n5. `__tests__/services/ContextOptimizerService.test.ts` - Tests\n\n### Database Tables Used\n- `prompt_optimizations`\n- `prompt_splits`\n- `document_embeddings`\n\n### Estimated Time: 2-3 days\n\n---\n\n## Service 3: AnalysisQueueService ‚è≥\n\n### Purpose\nPriority-based task management for heavy AI analysis with status tracking and result storage.\n\n### Key Features\n- ‚úÖ Priority queue (URGENT, HIGH, NORMAL, LOW)\n- ‚úÖ Status tracking (PENDING ‚Üí ANALYZING ‚Üí COMPLETED)\n- ‚úÖ Missing data identification\n- ‚úÖ Result storage and retrieval\n- ‚úÖ Performance metrics\n- ‚úÖ Queue monitoring\n\n### Implementation Tasks\n- [ ] Create queue management system\n- [ ] Implement priority scoring algorithm\n- [ ] Build status tracking\n- [ ] Add missing data detection\n- [ ] Create result storage system\n- [ ] Implement queue monitoring\n- [ ] Create API endpoints\n- [ ] Write unit tests\n- [ ] Add integration tests\n\n### Files to Create\n1. `lib/services/AnalysisQueueService.ts` - Main service\n2. `lib/types/queue.ts` - Type definitions\n3. `app/api/analysis/queue/route.ts` - API endpoint\n4. `lib/utils/priorityScorer.ts` - Priority scoring\n5. `__tests__/services/AnalysisQueueService.test.ts` - Tests\n\n### Database Tables Used\n- `analysis_queue`\n- `analysis_sessions`\n- `analysis_costs`\n\n### Estimated Time: 2-3 days\n\n---\n\n## Service 4: InstanceProvisionerService ‚è≥\n\n### Purpose\nEphemeral cloud instance management for cost-optimized GPU provisioning with automatic cleanup.\n\n### Key Features\n- ‚úÖ On-demand GPU instance provisioning\n- ‚úÖ Automatic termination after analysis\n- ‚úÖ Cost tracking and optimization\n- ‚úÖ Health monitoring\n- ‚úÖ 90% cost savings vs always-on instances\n- ‚úÖ Instance pooling for efficiency\n\n### Implementation Tasks\n- [ ] Create cloud provider integration (Azure/AWS)\n- [ ] Implement instance lifecycle management\n- [ ] Build cost tracking system\n- [ ] Add health monitoring\n- [ ] Create automatic cleanup logic\n- [ ] Implement instance pooling\n- [ ] Create API endpoints\n- [ ] Write unit tests\n- [ ] Add integration tests\n\n### Files to Create\n1. `lib/services/InstanceProvisionerService.ts` - Main service\n2. `lib/types/instance.ts` - Type definitions\n3. `lib/providers/azure.ts` - Azure provider\n4. `lib/providers/aws.ts` - AWS provider\n5. `app/api/instances/route.ts` - API endpoint\n6. `__tests__/services/InstanceProvisionerService.test.ts` - Tests\n\n### Database Tables Used\n- `cloud_instances`\n- `instance_costs`\n\n### Estimated Time: 3-4 days\n\n---\n\n## Implementation Timeline\n\n### Week 1: Foundation Services\n**Days 1-3:** LightweightChatbotService\n- Day 1: Service structure, OpenAI integration\n- Day 2: Context management, query classification\n- Day 3: Escalation, streaming, testing\n\n**Days 4-6:** ContextOptimizerService\n- Day 4: Context analysis, relevance scoring\n- Day 5: Token counting, compression\n- Day 6: Caching, metrics, testing\n\n### Week 2: Advanced Services\n**Days 7-9:** AnalysisQueueService\n- Day 7: Queue management, priority scoring\n- Day 8: Status tracking, result storage\n- Day 9: Monitoring, testing\n\n**Days 10-13:** InstanceProvisionerService\n- Day 10: Cloud provider integration\n- Day 11: Lifecycle management, cost tracking\n- Day 12: Health monitoring, cleanup\n- Day 13: Instance pooling, testing\n\n### Week 3: Integration & Testing\n**Days 14-16:** Integration\n- Day 14: Service integration\n- Day 15: End-to-end testing\n- Day 16: Performance optimization\n\n**Days 17-18:** Documentation & Deployment\n- Day 17: Documentation\n- Day 18: Deployment preparation\n\n---\n\n## Success Criteria\n\n### Performance Metrics\n- ‚úÖ Chatbot response time: <2 seconds\n- ‚úÖ Token reduction: 40%\n- ‚úÖ Cloud cost savings: 90%\n- ‚úÖ Queue processing time: <30 seconds\n- ‚úÖ Instance provisioning: <5 minutes\n\n### Quality Metrics\n- ‚úÖ Unit test coverage: >80%\n- ‚úÖ Integration test coverage: >70%\n- ‚úÖ API response time: <500ms\n- ‚úÖ Error rate: <1%\n- ‚úÖ Uptime: >99.9%\n\n### Code Quality\n- ‚úÖ TypeScript strict mode\n- ‚úÖ ESLint passing\n- ‚úÖ No console errors\n- ‚úÖ Proper error handling\n- ‚úÖ Comprehensive logging\n\n---\n\n## Dependencies\n\n### Required Packages\n```json\n{\n  "openai": "^5.23.2",           // Already installed\n  "@prisma/client": "^6.16.3",   // Already installed\n  "tiktoken": "^1.0.10",         // For token counting\n  "@azure/arm-compute": "^21.0.0", // Azure SDK\n  "aws-sdk": "^2.1500.0"         // AWS SDK\n}\n```\n\n### Environment Variables Needed\n```env\nOPENAI_API_KEY=your_key_here\nAZURE_SUBSCRIPTION_ID=your_id\nAZURE_CLIENT_ID=your_id\nAZURE_CLIENT_SECRET=your_secret\nAZURE_TENANT_ID=your_tenant\nAWS_ACCESS_KEY_ID=your_key\nAWS_SECRET_ACCESS_KEY=your_secret\nAWS_REGION=us-east-1\n```\n\n---\n\n## Current Status\n\n- ‚úÖ Phase 1: Documentation (Complete)\n- ‚úÖ Phase 2: Repository Architecture (Complete)\n- ‚úÖ Phase 3: Authentication & Consent (Complete)\n- ‚úÖ Phase 4: Patient Repository (Complete)\n- ‚úÖ Phase 5: Configuration & Maintenance (Complete)\n- ‚úÖ Phase 6: Database Setup (Complete)\n- ‚è≥ **Phase 7: Service Implementation (In Progress)**\n\n**Next Step:** Start implementing LightweightChatbotService\n\n---\n\n## Notes\n\n- All services will use the existing Prisma schema\n- Services will be built with TypeScript strict mode\n- Each service will have comprehensive error handling\n- All services will include logging and monitoring\n- Services will be designed for horizontal scaling\n- Cost tracking will be built into all AI operations\n\n</create-file>\n</function_calls>'}