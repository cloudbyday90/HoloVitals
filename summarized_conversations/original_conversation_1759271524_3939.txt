{'role': 'user', 'content': '<tool_result> <execute-command> ToolResult(success=True, output=\'{\\n  "output": "   /**\\\\n    * AI Provider Interface\\\\n    * \\\\n    * Abstract interface for all AI providers (OpenAI, Claude, etc.)\\\\n    * Enables easy switching between different AI models and providers.\\\\n    */\\\\n   \\\\n   export enum AIProvider {\\\\n     OPENAI = \\\'OPENAI\\\',\\\\n     CLAUDE = \\\'CLAUDE\\\',\\\\n     GEMINI = \\\'GEMINI\\\',\\\\n     LLAMA = \\\'LLAMA\\\'\\\\n   }\\\\n   \\\\n   export enum AIModel {\\\\n     // OpenAI Models\\\\n     GPT_35_TURBO = \\\'gpt-3.5-turbo\\\',\\\\n     GPT_4 = \\\'gpt-4\\\',\\\\n     GPT_4_TURBO = \\\'gpt-4-turbo\\\',\\\\n     GPT_4O = \\\'gpt-4o\\\',\\\\n     \\\\n     // Claude Models\\\\n     CLAUDE_3_OPUS = \\\'claude-3-opus-20240229\\\',\\\\n     CLAUDE_3_SONNET = \\\'claude-3-sonnet-20240229\\\',\\\\n     CLAUDE_3_HAIKU = \\\'claude-3-haiku-20240307\\\',\\\\n     CLAUDE_35_SONNET = \\\'claude-3-5-sonnet-20241022\\\',\\\\n     \\\\n     // Future: Gemini, Llama, etc.\\\\n   }\\\\n   \\\\n   export interface AIMessage {\\\\n     role: \\\'system\\\' | \\\'user\\\' | \\\'assistant\\\';\\\\n     content: string;\\\\n     name?: string;\\\\n   }\\\\n   \\\\n   export interface AICompletionRequest {\\\\n     messages: AIMessage[];\\\\n     model: AIModel;\\\\n     maxTokens?: number;\\\\n     temperature?: number;\\\\n     topP?: number;\\\\n     stream?: boolean;\\\\n     stopSequences?: string[];\\\\n     metadata?: Record<string, any>;\\\\n   }\\\\n   \\\\n   export interface AICompletionResponse {\\\\n     id: string;\\\\n     content: string;\\\\n",\\n  "exit_code": 0,\\n  "cwd": "/workspace"\\n}\') </execute-command> </tool_result>'}